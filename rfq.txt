
使用者操作流程如下:
1.使用者在前端選擇路徑後按下檢查，會列出PDF檔案列表
2.再按下分析後，後端會把檔案列表中有勾選的檔案，一份份進行分析，把關鍵字的數值提取出來
3.分析需要時間，所以使用者在前端會看到一個100%的進度條說明現在處理到哪裡了。
4.後端處理完一份就會將分析結果傳給前端，前端用列表接續顯示。使用者也能按下終止按鈕讓後端停止分析
5.當全部處理完後，使用者能下載xlsx

我的需求是:

1.請優化上面我的流程與前端介面。
2.將後端完整的實作，分析的實作，我之前有做好GUI app, 是在ref資料夾下，你可以參考該資料夾下的guiapp.py，以及主要的處理邏輯processing_module.py，
主要根據VLLM方式將所需關鍵字分析出來，整體邏輯你可以參考gui_app.py與processing_module.py與相關檔案的互動，必須參考或優化，可以複製內容但不要再引用ref的檔案(因為日後會將ref移除)
3.相關的設定，存放到.env中了，使用Azure AOAI與Document Intelligent的連線方式已經定義在.env, 變數如下，安全關係我把值都先移除，後續會補上:
# Azure AOAI
AZURE_OPENAI_ENDPOINT=""
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_DEPLOYMENT=""

# Azure Document Intelligence
DOCUMENT_INTELLIGENCE_ENDPOINT=""
DOCUMENT_INTELLIGENCE_KEY=""

4.每一個功能都要嚴格按照TDD方式執行，並要做好單元測試、功能測試、整合測試、系統測試等等

請列出你的執行計畫，估計要拆成幾個sprint?
請先列出來跟我討論後，再決定怎麼執行。

Prompt開始

  您好，我需要您扮演一位資深的 Python 開發專家，協助我重構一個現有專案的程式碼。

  主要目標：

  請修改我的 backend 應用程式中處理 PDF 文件的核心邏輯，使其處理流程與 ref/processing_module.py 中的邏輯保持一致。請注意：僅修改文件處理與分析的內部邏輯，不要改動任何 API
  端點、任務管理或其他非核心分析部分的程式碼。

  專案背景：

   * `backend`：這是一個 FastAPI Web 應用，它接收分析 PDF 的請求，並透過 LabelAnalysisService 類別來執行分析。
   * `ref/processing_module.py`：這是一個參考腳本，它包含了我們想要實現的目標處理邏輯。

  目前的 `backend` 處理邏輯 (`LabelAnalysisService`)：

  目前的邏輯是「多管齊下」。它會同時使用 FormatGuidedExtractor（範本座標擷取）、AzureDocumentIntelligenceExtractor（雲端 AI OCR）和 HeuristicAnalysisEngine（通用 AI
  分析），然後將所有來源的結果合併在一起。

  目標 `ref` 處理邏輯 (`processing_module.py`)：

  目標邏輯是「模式切換」，根據條件二選一：
   1. 模式 A (找到範本)：如果 PDF 檔名能對應到一個 .json 格式範本，就只使用該範本進行座標擷取。
   2. 模式 B (未找到範本)：如果找不到對應的範本，則啟用一個純 AI 流程：
       * 第一步：由 AI 預測出 PDF 中的關鍵頁面。
       * 第二步：將關鍵頁面截圖，並將整個頁面圖片交給另一個 AI (如 Azure DI 或 ChatGPT) 進行分析。

  ---

  詳細重構指令：

  請專注於修改 backend/document_analysis.py 檔案中的 LabelAnalysisService.analyse 方法。

   1. 修改 `analyse` 方法的內部實作：
       * 保留 async def analyse(self, pdf_path: Path) -> tuple[Dict[str, str], List[str]]: 的函式簽名不變。
       * 在方法內部，首先檢查 self.format_repository 是否存在，以及它是否能為傳入的 pdf_path 找到一個對應的 FormatSpec (就像 ref/processing_module.py 中比對檔名的邏輯一樣)。

   2. 實現「模式 A」邏輯：
       * 如果成功找到了 FormatSpec，則執行「模式 A」。
       * 在這個模式下，您應該只呼叫 self.extractor.extract(pdf_path, spec) (即 FormatGuidedExtractor) 來獲取結果。
       * 可以選擇性地呼叫 self.document_intelligence_extractor.extract(pdf_path, spec) 作為補充，但主要以範本擷取為主。
       * 將擷取到的欄位和處理訊息（例如 "使用格式樣板 XXX 進行處理"）準備好後返回。不要再呼叫通用的 self.analysis_engine。

   3. 實現「模式 B」邏輯：
       * 如果沒有找到 FormatSpec，則執行「模式 B」。
       * 這是需要您發揮創意的地方。您需要模擬 ref 版本中的 process_mode_b 流程。由於 backend 中目前沒有「預測頁面」和「整頁截圖分析」的現成函式，請您：
           * 建立兩個新的、可能是 placeholder 的 async 輔助函式，例如：
               * _predict_relevant_pages(self, pdf_path: Path) -> List[int]：此函式應回傳一個包含頁碼的列表。在實作中，您可以先讓它簡單地回傳 [1] 或文件的前幾頁。
               * _process_pages_with_full_page_ai(self, pdf_path: Path, pages: List[int]) -> Dict[str,
                 str]：此函式應模擬接收頁碼後，進行整頁分析並回傳結果。在實作中，您可以讓它直接呼叫現有的 self.analysis_engine.analyse(document) 作為替代。
           * 在 analyse 方法的「模式 B」分支中，依次呼叫這兩個新的輔助函式來完成分析流程。

   4. 保持回傳格式不變：
       * 無論是模式 A 還是模式 B，analyse 方法最終都必須回傳一個 tuple[Dict[str, str], List[str]]，其中包含擷取到的欄位字典和處理過程的訊息列表。

  總結：您的任務是將 LabelAnalysisService.analyse 從一個「結果合併」的邏輯，重構成一個「條件分支」(模式 A / 模式 B) 的邏輯，使其行為與 ref/processing_module.py 的核心思想對齊。

  請提供修改後的 backend/document_analysis.py 完整程式碼。

  我將實際的PDF放在test_pdf目錄下，你可以取其中幾份來做測試使用

  Prompt結束


A.流程請遵照我說的:
  1.先檢查有沒有format
  2a.如果有format檔案，那就照format中的page列表(如1,3,5..), 把該page轉成圖片
  2b.如果沒有對應的format檔案，那就先把PDF檔案拿去問chatgpt, 哪些頁面疑似有六個關鍵字訊息的，請chatgpt傳回可疑頁面數，然後將這些葉面轉成圖片
  3.將圖片對Azure的Intelligent document去做OCR解析，再將解析結果，去問chatgpt, 得到這六個關鍵字的值
  絕對不要照你說的只抓1-3頁。
  如果你對流程有不了解，可以參考ref目錄下的GUI_APP.py, 他是單機版，但可以運作。
  B.架構可以先照你的規劃做(分析引擎、整體資源...)


  1.在原本的前端頁面的左邊，增加顯示工作狀態: 最近的job排隊列表與各job的狀態(分析中/已完成/...)與時間
  2.使用者在原本的前端，按照原本的操作流程:輸入路徑、選擇要分析的檔案按下分析按鈕後，
  3.系統就會把指定的路徑的檔案，先備份到臨時的job資料夾內，並帶有jobid, 資料夾就用jobid為命名
  4.背景有一個處理程序，假設為cronjob, 它的作用就是按照時間，一份份把jobid拿來處理，處理流程與邏輯按照現在有的方式(辨識是否有format, 轉成圖片, 問di, 再問chatgpt..)
  5.處理的jobid資料夾，會有個檔案標示現在的處理狀態，也有log, 最後也會將結果寫成一份excel
  6.使用者可以看前端的工作狀態，點擊要看的jobid的內容，那麼就會顯示該jobid的處理哪些檔案、處理結果(並可下載excel), log紀錄
  7.當jobid處理完畢後，便可將pdf移除以免佔空間。
  8.整個過程與功能要照TDD(Test driven development)方式開發
  9.要考慮到多用戶同時操作的情境
  10.相關設定可以寫到.env或是setting裡，讓我知道哪些參數是可以設置的


   - 任務排程可緩衝：前端只要把分析需求轉成 job 寫入 queue/資料庫，再立即回覆「已排入處理」，使用者不需等同一個 worker 完成就能繼續操作，因此多位使用者同步新增 job 時不會互相卡住在前端。
  - 真正瓶頸在處理端：要確認 queue/worker 架構對效能有幫助，需確定背景處理具備足夠吞吐量（可水平擴充到多個 worker）與正確的鎖定/重試策略；否則只是把等待從 UI 移到 queue 內，仍可能累積大量未完成 job。
  - 可觀測性很重要：設計 job dashboard、處理時間統計、排隊長度與錯誤率，才能即時評估是否需要增加 worker 數量、調整資源或拆分任務流程，確保多人同時操作時系統仍流暢。




• Sprint 0 – Discovery & Architecture

  - Audit現有前後端流程、測試覆蓋率、部署模式；盤點可複用模組與技術債
  - 明確定義 Job lifecycle / 狀態機、資料夾命名、log/excel 格式、清理策略
  - 決定 queue 儲存層（sqlite / redis / DB）與 worker 執行框架；草擬 TDD 測試矩陣
  - 完成設定項目與 .env/settings 說明草稿；更新系統架構圖與資料流文件

  Sprint 1 – Queue Service & Domain TDD

  - 建立 Job domain 模組（建立/排程/鎖定/重試/失敗）與 repository 介面
  - 以 TDD 撰寫 unit/integration 測試：JobState transitions、併發鎖、超時/重試
  - 實作 queue persistence + API（建立/查詢/取消），採用 REST + SSE/WebSocket 草稿
  - 實作背景 worker skeleton（單 worker），串接既有處理管線（format 判斷→轉圖→di→GPT）
  - 增加測試 fixture 與暫存目錄隔離；提供初版 .env 設定值（暫存根目錄、max concurrency 等）

  Sprint 2 – 前端 Dashboard 與 Worker 擴充

  - 重構前端：左側工作狀態面板、job 詳細檢視與下載連結；導入即時更新機制
  - 為前端加上 component/unit/E2E 測試（mock SSE/websocket & API responses）
  - 擴充 worker：多 job 併發控制、狀態檔同步、log/excel 產出與儲存/下載端點
  - 實作 job 完成後清理策略（PDF/影像）、排程清理腳本與測試
  - 建立 error monitoring/logging 格式與接口（含 retry 上限與 dead-letter）

  Sprint 3 – 多使用者情境與品質收斂

  - 導入使用者識別（job ownership）、權限檢查、結果下載授權測試
  - 壓力測試/負載模擬：多使用者新增 job、worker crash/retry、冷啟動恢復
  - 強化觀測性：排隊長度/處理時間統計 API，前端顯示儀表與測試
  - 完成文件：TDD 流程紀錄、部署與設定指南、清理/備援手冊
  - 準備發佈：回顧測試矩陣、整理 release note、安排 UAT/回饋迭代



