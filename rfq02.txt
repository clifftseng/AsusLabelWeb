
  1.在原本的前端頁面的左邊，增加顯示工作狀態: 最近的job排隊列表與各job的狀態(分析中/已完成/...)與時間
  2.使用者在原本的前端，按照原本的操作流程:輸入路徑、選擇要分析的檔案按下分析按鈕後，
  3.系統就會把指定的路徑的檔案，先備份到臨時的job資料夾內，並帶有jobid, 資料夾就用jobid為命名
  4.背景有一個處理程序，假設為cronjob, 它的作用就是按照時間，一份份把jobid拿來處理，處理流程與邏輯按照現在有的方式(辨識是否有format, 轉成圖片, 問di, 再問chatgpt..)
  5.處理的jobid資料夾，會有個檔案標示現在的處理狀態，也有log, 最後也會將結果寫成一份excel
  6.使用者可以看前端的工作狀態，點擊要看的jobid的內容，那麼就會顯示該jobid的處理哪些檔案、處理結果(並可下載excel), log紀錄
  7.當jobid處理完畢後，便可將pdf移除以免佔空間。
  8.整個過程與功能要照TDD(Test driven development)方式開發
  9.要考慮到多用戶同時操作的情境
  10.相關設定可以寫到.env或是setting裡，讓我知道哪些參數是可以設置的


   - 任務排程可緩衝：前端只要把分析需求轉成 job 寫入 queue/資料庫，再立即回覆「已排入處理」，使用者不需等同一個 worker 完成就能繼續操作，因此多位使用者同步新增 job 時不會互相卡住在前端。
  - 真正瓶頸在處理端：要確認 queue/worker 架構對效能有幫助，需確定背景處理具備足夠吞吐量（可水平擴充到多個 worker）與正確的鎖定/重試策略；否則只是把等待從 UI 移到 queue 內，仍可能累積大量未完成 job。
  - 可觀測性很重要：設計 job dashboard、處理時間統計、排隊長度與錯誤率，才能即時評估是否需要增加 worker 數量、調整資源或拆分任務流程，確保多人同時操作時系統仍流暢。




• Sprint 0 – Discovery & Architecture

  - Audit現有前後端流程、測試覆蓋率、部署模式；盤點可複用模組與技術債
  - 明確定義 Job lifecycle / 狀態機、資料夾命名、log/excel 格式、清理策略
  - 決定 queue 儲存層（sqlite / redis / DB）與 worker 執行框架；草擬 TDD 測試矩陣
  - 完成設定項目與 .env/settings 說明草稿；更新系統架構圖與資料流文件

  Sprint 1 – Queue Service & Domain TDD

  - 建立 Job domain 模組（建立/排程/鎖定/重試/失敗）與 repository 介面
  - 以 TDD 撰寫 unit/integration 測試：JobState transitions、併發鎖、超時/重試
  - 實作 queue persistence + API（建立/查詢/取消），採用 REST + SSE/WebSocket 草稿
  - 實作背景 worker skeleton（單 worker），串接既有處理管線（format 判斷→轉圖→di→GPT）
  - 增加測試 fixture 與暫存目錄隔離；提供初版 .env 設定值（暫存根目錄、max concurrency 等）

  Sprint 2 – 前端 Dashboard 與 Worker 擴充

  - 重構前端：左側工作狀態面板、job 詳細檢視與下載連結；導入即時更新機制
  - 為前端加上 component/unit/E2E 測試（mock SSE/websocket & API responses）
  - 擴充 worker：多 job 併發控制、狀態檔同步、log/excel 產出與儲存/下載端點
  - 實作 job 完成後清理策略（PDF/影像）、排程清理腳本與測試
  - 建立 error monitoring/logging 格式與接口（含 retry 上限與 dead-letter）

  Sprint 3 – 多使用者情境與品質收斂

  - 導入使用者識別（job ownership）、權限檢查、結果下載授權測試
  - 壓力測試/負載模擬：多使用者新增 job、worker crash/retry、冷啟動恢復
  - 強化觀測性：排隊長度/處理時間統計 API，前端顯示儀表與測試
  - 完成文件：TDD 流程紀錄、部署與設定指南、清理/備援手冊
  - 準備發佈：回顧測試矩陣、整理 release note、安排 UAT/回饋迭代

