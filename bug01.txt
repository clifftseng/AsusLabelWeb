[推論（精簡版）]
- 現象：第 2 份 PDF 的某一頁送出 Azure DI 後，SDK 的 LRO（poller.result()）無逾時保護 → 卡在 worker thread 中，無例外、無 log、整批流程停滯。
- 主因：同步 DI 呼叫缺乏 timeout / cancel；逐頁建立 LRO，任一頁卡住即卡死全批。
- 解法總覽：
  A) 立即止血：保留同步 SDK，但在 poller 外層加「明確逾時 + 取消 + 降級」，逾時就略過該頁。
  B) 正式修復：改用 aio 客戶端 + asyncio.wait_for，且以「單次多頁」建立一個 LRO，降低卡死面積並能即時取消。
- 回退策略：若某頁(或多頁) DI 超時/失敗 → 回退 PyMuPDF 文字抽取，不中斷批次。

# A) 最小修補：在同步版本 _analyse_bytes() 加上逾時與取消（document_analysis.py）
# - 無需重構整個流程；保留你原本同步客戶端與逐頁處理
# - 逾時即略過該頁（回傳空字串），讓整批繼續跑

diff --git a/document_analysis.py b/document_analysis.py
@@
 class AzureDocumentIntelligenceExtractor:
     def __init__(self, endpoint: str, key: str, model_id: str = "prebuilt-document") -> None:
         ...
 
     def _analyse_bytes(self, image_bytes: bytes) -> str:
-        logger.debug("DI Extractor: Sending image to Azure DI for analysis.")
-        poller = self._client.begin_analyze_document(self._model_id, document=image_bytes)
-        result = poller.result()  # <-- 無逾時保護
-        logger.debug("DI Extractor: Received result from Azure DI.")
-        return self._parse_result_to_text(result)
+        import os, time, math
+        logger.debug("DI Extractor: Sending image to Azure DI for analysis.")
+        try:
+            poller = self._client.begin_analyze_document(self._model_id, document=image_bytes)
+        except Exception as exc:
+            logger.exception("DI Extractor: begin_analyze_document failed: %s", exc)
+            return ""
+
+        # ---- 新增：逾時與取消邏輯 ----
+        TIME_LIMIT_SEC = float(os.getenv("DI_PAGE_TIMEOUT_SEC", "60"))  # 可環境變數調整
+        POLL_GAP = float(os.getenv("DI_POLL_GAP_SEC", "2.0"))           # 輪詢間隔，避免忙等
+        start = time.monotonic()
+        try:
+            while True:
+                # 已完成：取結果並離開
+                if poller.done():
+                    try:
+                        result = poller.result()
+                        logger.debug("DI Extractor: Received result from Azure DI.")
+                        return self._parse_result_to_text(result)
+                    except Exception as exc:
+                        logger.exception("DI Extractor: poller.result() failed: %s", exc)
+                        return ""
+
+                # 逾時：取消並略過該頁
+                if time.monotonic() - start > TIME_LIMIT_SEC:
+                    try:
+                        poller.cancel()
+                    except Exception:
+                        pass
+                    logger.warning("DI Extractor: Timeout after %.1fs; skipping this page.", TIME_LIMIT_SEC)
+                    return ""
+
+                # 小睡一下，並持續輸出心跳，協助定位掛點
+                slept = min(POLL_GAP, max(0.2, TIME_LIMIT_SEC / 40.0))
+                logger.debug("DI Extractor: waiting... %.1fs elapsed", time.monotonic() - start)
+                time.sleep(slept)
+        except Exception as exc:
+            logger.exception("DI Extractor: unexpected polling error: %s", exc)
+            return ""

@@
     def extract_full_pages(self, pdf_path: Path, pages: List[int]) -> Dict[int, str]:
         # 保持你原本逐頁處理，但現在 _analyse_bytes() 不會卡死整批
         ...
# 推薦新增/調整的環境變數（.env）
DI_PAGE_TIMEOUT_SEC=60
DI_POLL_GAP_SEC=2.0

說明：

逾時 ⇒ poller.cancel() + 回傳空字串 ⇒ 後續管線繼續，不被單一頁拖垮。

加「心跳 log」可在 backend.log 中清楚看到等待狀態，便於定位。

若頁面真的拿不到 DI 文字，你的 Mode B 應回退到 PyMuPDF 的純文字抽取（維持整批可完成）。


# B) 正式重構：aio 客戶端 + 單次多頁 + asyncio.wait_for
# - 建議新增一個 Async 版本，逐步將 Mode B 切換到此路徑
# - 關鍵：用 pages="2,3,4" 一次建立 1 個 LRO，並以 asyncio.wait_for 實作真正逾時與可取消性

# document_analysis.py（示意：新增 Async 版本，不破壞舊的同步類別）
import asyncio
from pathlib import Path
from typing import Dict, List, Optional

from azure.core.credentials import AzureKeyCredential
from azure.ai.formrecognizer.aio import DocumentAnalysisClient as AioDIClient

class AzureDocumentIntelligenceExtractorAio:
    def __init__(self, endpoint: str, key: str, model_id: str = "prebuilt-document") -> None:
        self._endpoint = endpoint
        self._key = key
        self._model_id = model_id
        self._client: Optional[AioDIClient] = None

    async def _ensure_client(self) -> AioDIClient:
        if self._client is None:
            self._client = AioDIClient(self._endpoint, AzureKeyCredential(self._key))
        return self._client

    async def extract_pages_multi(self, pdf_path: Path, pages: List[int]) -> Dict[int, str]:
        """
        一次對多頁進行分析（單一 LOR poller），並以 asyncio.wait_for 加上逾時與取消。
        回傳 {page_number: text}；失敗/超時則回傳 {} 或部分頁面文本。
        """
        import os, logging
        logger = logging.getLogger(__name__)

        unique_pages = sorted(set(p for p in pages if p > 0))
        if not unique_pages:
            return {}

        client = await self._ensure_client()
        pdf_bytes = pdf_path.read_bytes()
        pages_arg = ",".join(str(p) for p in unique_pages)  # 例如 "2,3,4"

        POLL_TIMEOUT = float(os.getenv("DI_MULTI_TIMEOUT_SEC", "120"))

        logger.debug("DI AIO: begin_analyze_document pages=%s size=%d", pages_arg, len(pdf_bytes))
        poller = await client.begin_analyze_document(
            self._model_id,
            document=pdf_bytes,
            pages=pages_arg,
        )

        try:
            result = await asyncio.wait_for(poller.result(), timeout=POLL_TIMEOUT)
        except asyncio.TimeoutError:
            # 逾時：嘗試取消
            try:
                await poller.cancel()
            except Exception:
                pass
            logger.warning("DI AIO: Timeout after %.1fs for pages=%s", POLL_TIMEOUT, pages_arg)
            return {}
        except Exception as exc:
            logger.exception("DI AIO: analyse failed for pages=%s: %s", pages_arg, exc)
            return {}

        # 解析結果：優先依每頁 lines/content 組裝
        out: Dict[int, str] = {}
        try:
            # 若 SDK 物件帶有 pages 屬性，以 page_number 分發
            if getattr(result, "pages", None):
                for p in result.pages:
                    pnum = getattr(p, "page_number", None)
                    lines = [getattr(l, "content", "") for l in getattr(p, "lines", []) if getattr(l, "content", "")]
                    text = "\n".join(lines).strip()
                    if pnum and text:
                        out[pnum] = text
            # 備援：有些版本可由 result.content 取全文
            if not out and isinstance(getattr(result, "content", ""), str):
                text = result.content.strip()
                for p in unique_pages:
                    out[p] = text
        except Exception as exc:
            logger.exception("DI AIO: parse result failed: %s", exc)

        return out


    # 將 Mode B/呼叫點導到 AIO 版本（示意）
# 假設原本是同步：texts = di_extractor.extract_full_pages(pdf_path, pages)
# 現在改成：
- texts = await asyncio.to_thread(di_extractor.extract_full_pages, pdf_path, pages)
+ aio_extractor = AzureDocumentIntelligenceExtractorAio(settings.DI_ENDPOINT, settings.DI_KEY, settings.DI_MODEL_ID)
+ texts = await aio_extractor.extract_pages_multi(pdf_path, pages)
+ # 若 texts 為空，回退至原本 PyMuPDF 文字抽取
env

# 正式重構建議的環境變數
DI_MULTI_TIMEOUT_SEC=120
# 視服務端負載可再上調到 180~240；但務必保有硬逾時
text

[外掛驗證建議（本地可立即做）]
1) 加入 A 版「心跳 log」後，重跑問題文件批次，觀察 backend.log：
   - 頁面卡住時應每 2 秒出現一次 "waiting..." 訊息；
   - 60 秒後應出現 Timeout 警告，流程繼續處理下一頁/下一份文件。
2) 切換到 B 版 aio + 單次多頁：
   - 檢查單個 poller 是否能覆蓋所有 pages；
   - 手動觸發取消(若你有 UI/端點)時，能即時中斷當前 LRO；
   - 成功/逾時/失敗三種情境都不會阻斷整批任務。
text

[其他實務細節（可選，建議逐步導入）]
- 直接送 PDF bytes + pages（避免將頁面渲染成高 DPI PNG）：結果更穩、流量更小。
- 尊重 retry-after（aio SDK 通常內建處理），避免過度輪詢。
- 在批次之間加入 0.5~1s 節流，降低被限流機率。
- 將 azure-ai-formrecognizer / azure-core 版本與執行環境一致化（requirements 與實際 UA 對齊）。





範例:

# [A] 最小修補：為同步 LRO 加上逾時、取消與心跳日誌
# 目標檔：document_analysis.py
# 作用：避免 poller.result() 無限阻塞；逾時即略過該頁，讓整批不中斷。

diff --git a/document_analysis.py b/document_analysis.py
@@
 class AzureDocumentIntelligenceExtractor:
@@
     def _analyse_bytes(self, image_bytes: bytes) -> str:
-        logger.debug("DI Extractor: Sending image to Azure DI for analysis.")
-        poller = self._client.begin_analyze_document(self._model_id, document=image_bytes)
-        logger.debug("DI Extractor: Polling Azure DI for result.")
-        result = poller.result()
-        logger.debug("DI Extractor: Received result from Azure DI.")
-        if hasattr(result, "content") and isinstance(result.content, str):
-            logger.debug("DI Extractor: Returning content from result.")
-            return result.content.strip()
-        lines: List[str] = []
-        for page in getattr(result, "pages", []):
-            for line in getattr(page, "lines", []):
-                text = getattr(line, "content", "")
-                if text:
-                    lines.append(text)
-        logger.debug(f"DI Extractor: Returning {len(lines)} lines from result pages.")
-        return "\n".join(lines).strip()
+        import os, time
+        logger.debug("DI Extractor: Sending image to Azure DI for analysis.")
+        try:
+            poller = self._client.begin_analyze_document(self._model_id, document=image_bytes)
+        except Exception as exc:
+            logger.exception("DI Extractor: begin_analyze_document failed: %s", exc)
+            return ""
+
+        # ---- 明確逾時與取消邏輯（避免無限阻塞）----
+        TIME_LIMIT_SEC = float(os.getenv("DI_PAGE_TIMEOUT_SEC", "60"))   # 可用 .env 調整
+        POLL_GAP_SEC   = float(os.getenv("DI_POLL_GAP_SEC", "2.0"))      # 心跳輪詢間隔
+        start = time.monotonic()
+
+        while True:
+            try:
+                if poller.done():
+                    try:
+                        result = poller.result()
+                    except Exception as exc:
+                        logger.exception("DI Extractor: poller.result() failed: %s", exc)
+                        return ""
+                    logger.debug("DI Extractor: Received result from Azure DI.")
+                    # ---- 正常解析結果 ----
+                    if hasattr(result, "content") and isinstance(result.content, str):
+                        logger.debug("DI Extractor: Returning content from result.")
+                        return result.content.strip()
+                    lines: List[str] = []
+                    for page in getattr(result, "pages", []):
+                        for line in getattr(page, "lines", []):
+                            text = getattr(line, "content", "")
+                            if text:
+                                lines.append(text)
+                    logger.debug("DI Extractor: Returning %d lines from result pages.", len(lines))
+                    return "\n".join(lines).strip()
+            except Exception as exc:
+                logger.exception("DI Extractor: Polling error: %s", exc)
+                return ""
+
+            # 逾時處理：取消並略過該頁
+            elapsed = time.monotonic() - start
+            if elapsed > TIME_LIMIT_SEC:
+                try:
+                    poller.cancel()
+                except Exception:
+                    pass
+                logger.warning("DI Extractor: Timeout after %.1fs; skipping this page.", TIME_LIMIT_SEC)
+                return ""
+
+            # 心跳日誌，協助定位卡點
+            logger.debug("DI Extractor: waiting... %.1fs elapsed", elapsed)
+            time.sleep(max(0.2, min(POLL_GAP_SEC, TIME_LIMIT_SEC / 40.0)))
env
複製程式碼
# 建議加入（.env）
DI_PAGE_TIMEOUT_SEC=60
DI_POLL_GAP_SEC=2.0
diff
複製程式碼
# [B] 進階重構（可選）：改成「單次多頁 + 非同步客戶端 + 真正 asyncio 逾時」
# 新增 aio 版本，不破壞既有同步流程；日後可逐步切換呼叫點至 aio。
# 新增類別：AzureDocumentIntelligenceExtractorAio（document_analysis.py 內）

diff --git a/document_analysis.py b/document_analysis.py
@@
+import asyncio
+from typing import Dict, List, Optional
+from azure.core.credentials import AzureKeyCredential
+try:
+    from azure.ai.formrecognizer.aio import DocumentAnalysisClient as AioDocumentAnalysisClient
+except Exception:
+    AioDocumentAnalysisClient = None  # 避免未安裝時崩潰
+
+class AzureDocumentIntelligenceExtractorAio:
+    def __init__(self, *, endpoint: str, key: str, model_id: str = "prebuilt-document") -> None:
+        if AioDocumentAnalysisClient is None:
+            raise RuntimeError("azure-ai-formrecognizer aio 客戶端未安裝")
+        self._endpoint = endpoint
+        self._key = key
+        self._model_id = model_id
+        self._client: Optional[AioDocumentAnalysisClient] = None
+
+    async def _client_async(self) -> AioDocumentAnalysisClient:
+        if self._client is None:
+            self._client = AioDocumentAnalysisClient(self._endpoint, AzureKeyCredential(self._key))
+        return self._client
+
+    async def analyse_pdf_pages(self, pdf_path: Path, pages: List[int]) -> Dict[int, str]:
+        """
+        以「單一 LRO」分析多頁，並以 asyncio.wait_for 實作硬逾時。
+        回傳 {page_number: text}（部分成功時回傳已完成頁面）。
+        """
+        import os, logging
+        logger = logging.getLogger(__name__)
+
+        uniq = sorted(set(p for p in pages if p > 0))
+        if not uniq:
+            return {}
+
+        client = await self._client_async()
+        pdf_bytes = pdf_path.read_bytes()
+        pages_arg = ",".join(str(p) for p in uniq)  # 例如 "2,3,4"
+        timeout = float(os.getenv("DI_MULTI_TIMEOUT_SEC", "120"))
+
+        logger.debug("DI AIO: begin_analyze_document pages=%s size=%d", pages_arg, len(pdf_bytes))
+        poller = await client.begin_analyze_document(self._model_id, document=pdf_bytes, pages=pages_arg)
+        try:
+            result = await asyncio.wait_for(poller.result(), timeout=timeout)
+        except asyncio.TimeoutError:
+            try:
+                await poller.cancel()
+            except Exception:
+                pass
+            logger.warning("DI AIO: Timeout after %.1fs for pages=%s", timeout, pages_arg)
+            return {}
+        except Exception as exc:
+            logger.exception("DI AIO: analyse failed for pages=%s: %s", pages_arg, exc)
+            return {}
+
+        out: Dict[int, str] = {}
+        try:
+            if getattr(result, "pages", None):
+                for p in result.pages:
+                    pnum = getattr(p, "page_number", None)
+                    lines = [getattr(l, "content", "") for l in getattr(p, "lines", []) if getattr(l, "content", "")]
+                    text = "\n".join(lines).strip()
+                    if pnum and text:
+                        out[pnum] = text
+            if not out and isinstance(getattr(result, "content", ""), str):
+                text = result.content.strip()
+                for p in uniq:
+                    out[p] = text
+        except Exception as exc:
+            logger.exception("DI AIO: parse result failed: %s", exc)
+        return out
diff
複製程式碼
# [B-1]（可選）將 Mode B 呼叫點導向 AIO（示意）
# 若要在不大改架構的情況下測試 AIO，於 LabelAnalysisService._gather_page_texts 前先建立 aio extractor。
# 假設 settings 有 DOCUMENT_INTELLIGENCE_ENDPOINT/DOCUMENT_INTELLIGENCE_KEY

diff --git a/document_analysis.py b/document_analysis.py
@@ class LabelAnalysisService:
-        try:
-            texts = await self.document_intelligence_extractor.extract_full_pages(pdf_path, pages)
+        try:
+            # --- AIO 路徑（可切換開關）---
+            use_aio = bool(os.getenv("DI_USE_AIO", "0") == "1")
+            if use_aio:
+                endpoint = os.getenv("DOCUMENT_INTELLIGENCE_ENDPOINT", "")
+                key = os.getenv("DOCUMENT_INTELLIGENCE_KEY", "")
+                aio = AzureDocumentIntelligenceExtractorAio(endpoint=endpoint, key=key, model_id=os.getenv("DOCUMENT_INTELLIGENCE_MODEL", "prebuilt-document"))
+                texts = await aio.analyse_pdf_pages(pdf_path, pages)
+            else:
+                texts = await self.document_intelligence_extractor.extract_full_pages(pdf_path, pages)
         except Exception as exc:  # pragma: no cover - defensive path
             logger.exception(f"[Mode B] Document Intelligence failed for {pdf_path.name}: {exc}")
             return {}
env
複製程式碼
# 若採 AIO 版本（可選）
DI_MULTI_TIMEOUT_SEC=120
DI_USE_AIO=1
# 亦可在 .env 關閉（設為 0）回到同步路徑
bash
複製程式碼
# [驗證建議腳本（本地）]：觀察逾時與不中斷
# 1) 設定較短逾時測試最小修補
export DI_PAGE_TIMEOUT_SEC=10
export DI_POLL_GAP_SEC=1.0
# 2) 跑你原本的批量端點，觀察 backend.log 應出現：
#    - waiting... 心跳
#    - Timeout after 10.0s; skipping this page.
#    - 之後繼續處理下一頁/下一份文件
#
# 若採 AIO：
export DI_USE_AIO=1
export DI_MULTI_TIMEOUT_SEC=30
# 重新執行，確認單一 LRO 覆蓋多頁，且逾時時能立即取消不中斷。
